#!/usr/bin/env python3
"""
Train RUNE NER with ModernBERT streaming dataset.
Uses ModernBERT's 8192 token context to handle longer stories.
"""

import os
import json
import torch
from typing import Iterator, Dict, Any
from torch.utils.data import IterableDataset
from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification,
    EarlyStoppingCallback,
)
from seqeval.metrics import f1_score, accuracy_score
from rune.data.story_preprocessor import StoryPreprocessor


class ModernBERTStreamingDataset(IterableDataset):
    """Streaming dataset for ModernBERT with optional length filtering."""

    def __init__(
        self,
        jsonl_path: str,
        tokenizer,
        max_length: int = 8192,
        skip: int = 0,
        limit: int = None,
        prefiltered: bool = False,
        simplify_labels: bool = False,
    ):
        """
        Initialize streaming dataset.

        Args:
            jsonl_path: Path to JSONL file
            tokenizer: ModernBERT tokenizer
            max_length: Max sequence length (8192 for ModernBERT)
            skip: Number of stories to skip
            limit: Max stories to process
            prefiltered: If True, assumes data is pre-processed with tokens/bio_tags
            simplify_labels: If True, collapse role labels to B-PERSON/I-PERSON
        """
        self.jsonl_path = jsonl_path
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.skip = skip
        self.limit = limit
        self.prefiltered = prefiltered
        self.simplify_labels = simplify_labels

        # Initialize preprocessor if not prefiltered
        if not prefiltered:
            self.preprocessor = StoryPreprocessor(use_spacy=False)

        # Label mappings
        if simplify_labels:
            # Simplified B/I/O for entity detection only
            self.label_to_id = {
                'O': 0,
                'B-PERSON': 1,
                'I-PERSON': 2,
                'B-LOCATION': 3,
                'I-LOCATION': 4,
            }
            # Map role labels to simplified labels
            self.role_to_simple = {
                'B-PROTAGONIST': 'B-PERSON',
                'I-PROTAGONIST': 'I-PERSON',
                'B-ANTAGONIST': 'B-PERSON',
                'I-ANTAGONIST': 'I-PERSON',
                'B-SUPPORTING': 'B-PERSON',
                'I-SUPPORTING': 'I-PERSON',
                'B-LOCATION': 'B-LOCATION',
                'I-LOCATION': 'I-LOCATION',
                'O': 'O',
            }
        else:
            # Full role-aware labels
            self.label_to_id = {
                'O': 0,
                'B-ANTAGONIST': 1,
                'B-PROTAGONIST': 2,
                'B-SUPPORTING': 3,
                'I-ANTAGONIST': 4,
                'I-PROTAGONIST': 5,
                'I-SUPPORTING': 6,
            }
            self.role_to_simple = None

        self.id_to_label = {v: k for k, v in self.label_to_id.items()}

    def __iter__(self) -> Iterator[Dict[str, Any]]:
        """Iterate over stories."""
        with open(self.jsonl_path, 'r', encoding='utf-8') as f:
            # Skip for train/val split
            for _ in range(self.skip):
                next(f)

            count = 0
            filtered_count = 0

            for line in f:
                if self.limit and count >= self.limit:
                    break

                try:
                    raw_story = json.loads(line.strip())

                    # Get or create processed story
                    if self.prefiltered:
                        # Already has tokens and bio_tags
                        processed = raw_story
                    else:
                        # Need to preprocess
                        processed = self.preprocessor.process_story(raw_story)

                    # Check token length
                    tokens = processed["tokens"]
                    test_tokenized = self.tokenizer(
                        tokens,
                        is_split_into_words=True,
                        truncation=False,
                        add_special_tokens=True
                    )
                    token_length = len(test_tokenized["input_ids"])

                    # Filter if too long
                    if token_length > self.max_length:
                        filtered_count += 1
                        continue

                    # Tokenize and align labels
                    tokenized = self._tokenize_and_align_labels(processed)

                    yield tokenized
                    count += 1

                except Exception as e:
                    print(f"âš ï¸  Error processing story: {e}")
                    continue

            if filtered_count > 0:
                print(f"ğŸ“Š Filtered {filtered_count} stories exceeding {self.max_length} tokens")
            print(f"âœ… Yielded {count} stories within token limit")

    def _tokenize_and_align_labels(self, story: Dict[str, Any]) -> Dict[str, Any]:
        """Tokenize story and align labels."""
        tokens = story["tokens"]
        bio_tags = story["bio_tags"]

        # Tokenize
        tokenized_inputs = self.tokenizer(
            tokens,
            truncation=True,
            is_split_into_words=True,
            max_length=self.max_length,
            padding="max_length",
            return_tensors="pt",
        )

        # Align labels
        word_ids = tokenized_inputs.word_ids()
        labels = []
        previous_word_idx = None

        for word_idx in word_ids:
            if word_idx is None:
                labels.append(-100)
            elif word_idx != previous_word_idx:
                tag = bio_tags[word_idx]
                # Apply simplification if enabled
                if self.simplify_labels and self.role_to_simple:
                    tag = self.role_to_simple.get(tag, tag)
                labels.append(self.label_to_id.get(tag, 0))
            else:
                labels.append(-100)
            previous_word_idx = word_idx

        return {
            "input_ids": tokenized_inputs["input_ids"].squeeze(0),
            "attention_mask": tokenized_inputs["attention_mask"].squeeze(0),
            "labels": torch.tensor(labels, dtype=torch.long),
        }


def create_compute_metrics(label_list):
    """Create metrics computation function."""
    def compute_metrics(eval_pred):
        predictions, labels = eval_pred
        predictions = predictions.argmax(axis=-1)

        true_predictions = [
            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
            for prediction, label in zip(predictions, labels)
        ]
        true_labels = [
            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]
            for prediction, label in zip(predictions, labels)
        ]

        flat_true = [item for sublist in true_labels for item in sublist]
        flat_pred = [item for sublist in true_predictions for item in sublist]

        if len(flat_true) == 0:
            return {"accuracy": 0.0}

        fine_grained_f1 = f1_score(true_labels, true_predictions)
        token_accuracy = accuracy_score(true_labels, true_predictions)

        true_binary = [
            ["ENTITY" if label != "O" else "O" for label in sequence]
            for sequence in true_labels
        ]
        pred_binary = [
            ["ENTITY" if label != "O" else "O" for label in sequence]
            for sequence in true_predictions
        ]
        entity_detection_f1 = f1_score(true_binary, pred_binary)

        entity_correct = sum(1 for t, p in zip(flat_true, flat_pred) if t != 'O' and t == p)
        entity_total = sum(1 for t in flat_true if t != 'O')
        entity_accuracy = entity_correct / entity_total if entity_total > 0 else 0

        return {
            "f1": fine_grained_f1,
            "accuracy": token_accuracy,
            "entity_detection_f1": entity_detection_f1,
            "entity_accuracy": entity_accuracy,
        }

    return compute_metrics


def main():
    """Main training function with curriculum support."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Train NER model with optional curriculum learning",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Single-stage training
  python3 train_modernbert_streaming.py --input data.jsonl --output ./model --model answerdotai/ModernBERT-base
  
  # Curriculum training (2 stages)
  python3 train_modernbert_streaming.py \\
    --model allenai/longformer-base-4096 \\
    --curriculum \\
    --curriculum-stage1-input diverse_phase1.jsonl \\
    --curriculum-stage2-input diverse_phase2.jsonl \\
    --curriculum-stage1-epochs 2 \\
    --curriculum-stage2-epochs 3 \\
    --output ./model \\
    --batch-size 4 \\
    --use-bf16
"""
    )
    
    # Model and data
    parser.add_argument('--model', default="answerdotai/ModernBERT-base", help="HuggingFace model name")
    parser.add_argument('--input', default=None, help="Input JSONL file (single-stage)")
    parser.add_argument('--output', default="./story_ner_model", help="Output directory")
    parser.add_argument('--max-length', type=int, default=None, help="Max token length (auto-detect from data if not set)")
    parser.add_argument('--stage1-max-length', type=int, default=1024, help="Stage 1 max length (short examples)")
    parser.add_argument('--stage2-max-length', type=int, default=4096, help="Stage 2 max length (long examples)")
    
    # Curriculum learning
    parser.add_argument('--curriculum', action='store_true', help="Enable curriculum learning (2 stages)")
    parser.add_argument('--curriculum-stage1-input', default=None, help="Stage 1 input (easy examples)")
    parser.add_argument('--curriculum-stage2-input', default=None, help="Stage 2 input (hard examples)")
    parser.add_argument('--curriculum-stage1-epochs', type=int, default=2, help="Stage 1 epochs")
    parser.add_argument('--curriculum-stage2-epochs', type=int, default=3, help="Stage 2 epochs")
    
    # Training config
    parser.add_argument('--batch-size', type=int, default=None, help="Per-device batch size (both stages if not specified separately)")
    parser.add_argument('--stage1-batch-size', type=int, default=None, help="Stage 1 batch size (defaults to --batch-size or 8)")
    parser.add_argument('--stage2-batch-size', type=int, default=None, help="Stage 2 batch size (defaults to --batch-size or 4)")
    parser.add_argument('--gradient-accumulation', type=int, default=1, help="Gradient accumulation steps")
    parser.add_argument('--learning-rate', type=float, default=5e-5, help="Learning rate")
    parser.add_argument('--use-bf16', action='store_true', help="Use bfloat16 mixed precision")
    
    # Resuming
    parser.add_argument('--resume-from-checkpoint', default=None, help="Resume from checkpoint path")
    
    # Labels
    parser.add_argument('--simplify-labels', action='store_true', help="Collapse role labels to B/I-PERSON")
    
    args = parser.parse_args()
    
    # Validate arguments
    if args.curriculum:
        if not args.curriculum_stage1_input or not args.curriculum_stage2_input:
            parser.error("--curriculum requires --curriculum-stage1-input and --curriculum-stage2-input")
    elif not args.input:
        parser.error("--input required for single-stage training (or use --curriculum)")
    
    print("ğŸš€ TRAINING RUNE NER")
    print("=" * 70)
    print(f"ğŸ¤– Model: {args.model}")
    print(f"ğŸ’¾ Max length: {args.max_length} tokens")
    if args.curriculum:
        print("ğŸ“ Mode: Curriculum learning (2 stages)")
        print(f"   Stage 1: {args.curriculum_stage1_input} ({args.curriculum_stage1_epochs} epochs)")
        print(f"   Stage 2: {args.curriculum_stage2_input} ({args.curriculum_stage2_epochs} epochs)")
    else:
        print("ğŸ“– Mode: Single-stage training")
        print(f"   Input: {args.input}")
    if args.simplify_labels:
        print("ğŸ”„ Labels: Simplified B/I-PERSON (role-agnostic)")
    else:
        print("ğŸ­ Labels: Full role-aware (B-PROTAGONIST, etc.)")
    print(f"ğŸ’¾ Output: {args.output}")
    if args.resume_from_checkpoint:
        print(f"â™»ï¸  Resuming from: {args.resume_from_checkpoint}")
    print("=" * 70)
    print()

    # Configuration
    model_name = args.model
    # Set max_length based on mode
    if args.curriculum:
        stage1_max_length = args.stage1_max_length
        stage2_max_length = args.stage2_max_length
        max_length = stage1_max_length  # For initial display
    else:
        max_length = args.max_length or 8192
    
    training_file = args.input if not args.curriculum else args.curriculum_stage1_input

    # Count total stories
    with open(training_file, "r") as f:
        total_stories = sum(1 for _ in f)

    print(f"ğŸ“š Total clean stories: {total_stories}")
    if args.curriculum:
        print(f"   Stage 1 max length: {stage1_max_length} tokens")
        print(f"   Stage 2 max length: {stage2_max_length} tokens")
    else:
        print(f"   Max token length: {max_length}")
    print(f"   All stories fit within token limit (pre-filtered)")
    print()

    # Calculate split
    val_split_idx = int(0.9 * total_stories)
    train_count = val_split_idx
    val_count = total_stories - val_split_idx

    print(f"ğŸ“Š Train/Val Split:")
    print(f"   Training: {train_count} stories")
    print(f"   Validation: {val_count} stories")
    print()

    # Load ModernBERT tokenizer and model
    print(f"ğŸ”„ Loading ModernBERT...")
    # Load tokenizer with add_prefix_space for Longformer
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        add_prefix_space=True  # Required for Longformer with pretokenized inputs
    )

    # Configure labels based on simplify_labels flag
    if args.simplify_labels:
        label_to_id = {
            'O': 0,
            'B-PERSON': 1,
            'I-PERSON': 2,
            'B-LOCATION': 3,
            'I-LOCATION': 4,
        }
    else:
        label_to_id = {
            'O': 0,
            'B-ANTAGONIST': 1,
            'B-PROTAGONIST': 2,
            'B-SUPPORTING': 3,
            'I-ANTAGONIST': 4,
            'I-PROTAGONIST': 5,
            'I-SUPPORTING': 6,
        }
    id_to_label = {v: k for k, v in label_to_id.items()}

    model = AutoModelForTokenClassification.from_pretrained(
        model_name,
        num_labels=len(label_to_id),
        id2label=id_to_label,
        label2id=label_to_id,
    )
    print(f"âœ… ModernBERT loaded with {len(label_to_id)} labels")
    print(f"   Labels: {', '.join(label_to_id.keys())}")
    print(f"   Max position embeddings: {model.config.max_position_embeddings}")
    print()

    # Create streaming datasets
    print("ğŸ”„ Creating streaming datasets...")
    train_dataset = ModernBERTStreamingDataset(
        training_file,
        tokenizer,
        max_length=max_length,
        skip=0,
        limit=train_count,
        prefiltered=True,  # Data is already pre-processed
        simplify_labels=args.simplify_labels
    )

    val_dataset = ModernBERTStreamingDataset(
        training_file,
        tokenizer,
        max_length=max_length,
        skip=val_split_idx,
        limit=val_count,
        prefiltered=True,  # Data is already pre-processed
        simplify_labels=args.simplify_labels
    )
    print("âœ… Streaming datasets created (using pre-filtered data)")
    print()

    # Output directory
    output_dir = args.output
    os.makedirs(output_dir, exist_ok=True)

    # Training arguments
    bf16_enabled = args.use_bf16 and torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8
    fp16_enabled = not bf16_enabled and torch.cuda.is_available()
    
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=3,  # Overridden per stage in curriculum mode
        per_device_train_batch_size=args.batch_size,
        per_device_eval_batch_size=args.batch_size,
        warmup_steps=500,
        weight_decay=0.01,
        learning_rate=args.learning_rate,
        logging_dir=f"{output_dir}/logs",
        logging_steps=100,
        eval_strategy="steps",
        eval_steps=500,
        save_strategy="steps",
        save_steps=500,
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
        gradient_accumulation_steps=args.gradient_accumulation,
        report_to=None,
        save_total_limit=3,
        bf16=bf16_enabled,
        fp16=fp16_enabled,
        dataloader_num_workers=0,
    )
    
    if bf16_enabled:
        print(f"âœ… Using bfloat16 mixed precision")
    elif fp16_enabled:
        print(f"âœ… Using float16 mixed precision")
    print()

    # Data collator
    data_collator = DataCollatorForTokenClassification(
        tokenizer,
        pad_to_multiple_of=8,
        return_tensors="pt"
    )

    # CURRICULUM TRAINING or SINGLE-STAGE
    if args.curriculum:
        # Determine batch sizes per stage
        if args.batch_size is not None:
            # --batch-size overrides both
            stage1_batch_size = args.batch_size
            stage2_batch_size = args.batch_size
        else:
            # Use stage-specific or defaults
            stage1_batch_size = args.stage1_batch_size or 8  # Bigger for short sequences
            stage2_batch_size = args.stage2_batch_size or 4  # Smaller for long sequences
        
        # Allow override
        if args.stage1_batch_size:
            stage1_batch_size = args.stage1_batch_size
        if args.stage2_batch_size:
            stage2_batch_size = args.stage2_batch_size
        
        print(f"ğŸ“ CURRICULUM LEARNING: Stage 1 (Easy)")
        print("=" * 70)
        print(f"ğŸ“Š Stage 1 batch size: {stage1_batch_size} (short sequences, 1024 tokens)")
        print(f"ğŸ“Š Stage 2 batch size: {stage2_batch_size} (long sequences, 4096 tokens)")
        print()
        
        # Count examples in each stage (wc -l)
        with open(args.curriculum_stage1_input) as f:
            stage1_count = sum(1 for _ in f)
        with open(args.curriculum_stage2_input) as f:
            stage2_count = sum(1 for _ in f)
        
        print(f"ğŸ“Š Stage 1: {stage1_count:,} examples")
        print(f"ğŸ“Š Stage 2: {stage2_count:,} examples")
        
        # Calculate max_steps for each stage
        stage1_effective_batch = stage1_batch_size * args.gradient_accumulation
        stage2_effective_batch = stage2_batch_size * args.gradient_accumulation
        stage1_steps = (stage1_count // stage1_effective_batch) * args.curriculum_stage1_epochs
        stage2_steps = (stage2_count // stage2_effective_batch) * args.curriculum_stage2_epochs
        
        print(f"ğŸ“ˆ Stage 1: batch={stage1_batch_size}, grad_accum={args.gradient_accumulation}, effective={stage1_effective_batch}, steps={stage1_steps:,}")
        print(f"ğŸ“ˆ Stage 2: batch={stage2_batch_size}, grad_accum={args.gradient_accumulation}, effective={stage2_effective_batch}, steps={stage2_steps:,}")
        print()
        
        # Stage 1: Easy examples
        stage1_output = f"{output_dir}/stage1"
        os.makedirs(stage1_output, exist_ok=True)
        
        stage1_args = TrainingArguments(
            output_dir=stage1_output,
            max_steps=stage1_steps,
            per_device_train_batch_size=stage1_batch_size,
            per_device_eval_batch_size=stage1_batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            learning_rate=args.learning_rate,
            logging_dir=f"{stage1_output}/logs",
            logging_steps=100,
            eval_strategy="steps",
            eval_steps=500,
            save_strategy="steps",
            save_steps=500,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            gradient_accumulation_steps=args.gradient_accumulation,
            report_to=None,
            save_total_limit=3,
            bf16=bf16_enabled,
            fp16=fp16_enabled,
            dataloader_num_workers=0,
        )
        
        # Stage 1 datasets
        stage1_train = ModernBERTStreamingDataset(
            args.curriculum_stage1_input,
            tokenizer,
            max_length=stage1_max_length,
            prefiltered=True,
            simplify_labels=args.simplify_labels
        )
        stage1_val = ModernBERTStreamingDataset(
            args.curriculum_stage1_input,
            tokenizer,
            max_length=stage1_max_length,
            skip=int(0.95 * total_stories),
            prefiltered=True,
            simplify_labels=args.simplify_labels
        )
        
        stage1_trainer = Trainer(
            model=model,
            args=stage1_args,
            train_dataset=stage1_train,
            eval_dataset=stage1_val,
            tokenizer=tokenizer,
            data_collator=data_collator,
            compute_metrics=create_compute_metrics(list(id_to_label.values())),
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
        )
        
        print(f"ğŸ‹ï¸ Stage 1 training ({args.curriculum_stage1_epochs} epochs)...")
        if args.curriculum_stage1_epochs > 0:
            resume_checkpoint = args.resume_from_checkpoint if args.resume_from_checkpoint and "stage1" in args.resume_from_checkpoint else None
            stage1_trainer.train(resume_from_checkpoint=resume_checkpoint)
            stage1_trainer.save_model()
            tokenizer.save_pretrained(stage1_output)
            print(f"âœ… Stage 1 complete. Saved to: {stage1_output}\n")
        else:
            print(f"â­ï¸  Skipping Stage 1 (0 epochs)\n")
        
        # Stage 2: Hard examples (fine-tune from stage 1)
        print(f"ğŸ“ CURRICULUM LEARNING: Stage 2 (Hard)")
        print("=" * 70)
        
        stage2_output = f"{output_dir}/stage2"
        os.makedirs(stage2_output, exist_ok=True)
        
        # Load stage 1 model or resume checkpoint
        if args.resume_from_checkpoint and "stage2" in args.resume_from_checkpoint:
            print(f"â™»ï¸  Resuming Stage 2 from: {args.resume_from_checkpoint}")
            model_stage2 = AutoModelForTokenClassification.from_pretrained(args.resume_from_checkpoint)
        elif args.curriculum_stage1_epochs > 0:
            print(f"ğŸ“¥ Loading Stage 1 model from: {stage1_output}")
            model_stage2 = AutoModelForTokenClassification.from_pretrained(stage1_output)
        else:
            print(f"ğŸ“¥ Using base model (Stage 1 skipped)")
            model_stage2 = model
        
        stage2_args = TrainingArguments(
            output_dir=stage2_output,
            max_steps=stage2_steps,
            per_device_train_batch_size=stage2_batch_size,
            per_device_eval_batch_size=stage2_batch_size,
            warmup_steps=500,
            weight_decay=0.01,
            learning_rate=args.learning_rate,
            logging_dir=f"{stage2_output}/logs",
            logging_steps=100,
            eval_strategy="steps",
            eval_steps=500,
            save_strategy="steps",
            save_steps=500,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            gradient_accumulation_steps=args.gradient_accumulation,
            report_to=None,
            save_total_limit=3,
            bf16=bf16_enabled,
            fp16=fp16_enabled,
            dataloader_num_workers=0,
        )
        
        # Stage 2 datasets
        stage2_train = ModernBERTStreamingDataset(
            args.curriculum_stage2_input,
            tokenizer,
            max_length=stage2_max_length,
            prefiltered=True,
            simplify_labels=args.simplify_labels
        )
        stage2_val = ModernBERTStreamingDataset(
            args.curriculum_stage2_input,
            tokenizer,
            max_length=stage2_max_length,
            skip=int(0.95 * total_stories),
            prefiltered=True,
            simplify_labels=args.simplify_labels
        )
        
        stage2_trainer = Trainer(
            model=model_stage2,
            args=stage2_args,
            train_dataset=stage2_train,
            eval_dataset=stage2_val,
            tokenizer=tokenizer,
            data_collator=data_collator,
            compute_metrics=create_compute_metrics(list(id_to_label.values())),
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
        )
        
        print(f"ğŸ‹ï¸ Stage 2 training ({args.curriculum_stage2_epochs} epochs)...")
        resume_checkpoint = args.resume_from_checkpoint if args.resume_from_checkpoint and "stage2" in args.resume_from_checkpoint else None
        stage2_trainer.train(resume_from_checkpoint=resume_checkpoint)
        stage2_trainer.save_model()
        tokenizer.save_pretrained(stage2_output)
        
        # Final eval
        print(f"\nğŸ“Š Final evaluation on Stage 2...")
        eval_results = stage2_trainer.evaluate()
        
        print(f"\nğŸ“ˆ FINAL RESULTS:")
        for key, value in eval_results.items():
            if key.startswith('eval_'):
                metric_name = key.replace('eval_', '').upper()
                print(f"   {metric_name}: {value:.4f}")
        
        print(f"\nğŸ‰ CURRICULUM TRAINING COMPLETE!")
        print(f"ğŸ“ Stage 1: {stage1_output}")
        print(f"ğŸ“ Stage 2 (final): {stage2_output}")
        
        final_model_path = stage2_output
        
    else:
        # SINGLE-STAGE TRAINING
        print(f"ğŸ‹ï¸ Single-stage training...")
        print("=" * 70)
        
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=tokenizer,
            data_collator=data_collator,
            compute_metrics=create_compute_metrics(list(id_to_label.values())),
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
        )
        
        resume_checkpoint = args.resume_from_checkpoint
        trainer.train(resume_from_checkpoint=resume_checkpoint)
        trainer.save_model()
        tokenizer.save_pretrained(output_dir)
        
        # Final eval
        print(f"\nğŸ“Š Final evaluation...")
        eval_results = trainer.evaluate()
        
        print(f"\nğŸ“ˆ FINAL RESULTS:")
        for key, value in eval_results.items():
            if key.startswith('eval_'):
                metric_name = key.replace('eval_', '').upper()
                print(f"   {metric_name}: {value:.4f}")
        
        print(f"\nğŸ‰ TRAINING COMPLETE!")
        print(f"ğŸ“ Model saved to: {output_dir}")
        
        final_model_path = output_dir

    # Metadata
    import json as js
    metadata = {
        "model": model_name,
        "max_token_length": max_length,
        "total_stories": total_stories,
        "streaming": True,
        "label_mapping": label_to_id,
        "curriculum": args.curriculum,
    }
    with open(f"{final_model_path}/training_metadata.json", "w") as f:
        js.dump(metadata, f, indent=2)

    print()
    return 0


if __name__ == "__main__":
    try:
        exit(main())
    except Exception as e:
        print(f"\nâŒ TRAINING FAILED: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
